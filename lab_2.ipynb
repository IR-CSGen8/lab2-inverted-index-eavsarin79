{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d8d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'John',\n",
       " 'Doe',\n",
       " 'Getting',\n",
       " 'Started',\n",
       " 'Python',\n",
       " 'is',\n",
       " 'a',\n",
       " 'versatile',\n",
       " 'programming',\n",
       " 'language...',\n",
       " 'Basic',\n",
       " 'Syntax',\n",
       " 'Python',\n",
       " 'syntax',\n",
       " 'is',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'understand...']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV dataset\n",
    "df = pd.read_csv(\"semi_strut.csv\")\n",
    "# Display the first few rows of the dataset\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "#  Tokenization function to extract terms from the JSON-like content\n",
    "# Remember to exact both \n",
    "# 1 .Extract terms from various fields (title, author)\n",
    "def tokenize_content(content):\n",
    "    content_dict = json.loads(content)\n",
    "    terms = []\n",
    "    \n",
    "    # Extract terms from various fields (title, author)\n",
    "    terms.extend(content_dict.get(\"title\", \"\").split())\n",
    "    terms.extend(content_dict.get(\"author\", \"\").split())\n",
    "\n",
    "    #extract terms from sections title and content\n",
    "    sections = content_dict.get(\"sections\",[])\n",
    "    for section in sections:\n",
    "        terms.extend(section.get(\"title\",\"\").split())\n",
    "        terms.extend(section.get(\"content\",\"\").split())\n",
    "        \n",
    "    return terms\n",
    "tokenize_content(df[\"Content\"][0])\n",
    "\n",
    "# lis=df[\"Content\"]\n",
    "# lis[0]\n",
    "# import json\n",
    "# res=json.loads(lis[0])\n",
    "\n",
    "\n",
    "# res\n",
    "# res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a073d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Analysis',\n",
       " 'Basic',\n",
       " 'Clark',\n",
       " 'Creating',\n",
       " 'Data',\n",
       " 'DataFrames',\n",
       " 'Davis',\n",
       " 'Development',\n",
       " 'Doe',\n",
       " 'Emily',\n",
       " 'Flask',\n",
       " 'Getting',\n",
       " 'Introduction',\n",
       " 'Jane',\n",
       " 'John',\n",
       " 'Johnson',\n",
       " 'Learning',\n",
       " 'Machine',\n",
       " 'Matplotlib',\n",
       " 'Mike',\n",
       " 'Pandas',\n",
       " 'Pandas...',\n",
       " 'Plots',\n",
       " 'Python',\n",
       " 'Python...',\n",
       " 'Robert',\n",
       " 'Routing',\n",
       " 'Scikit-Learn',\n",
       " 'Smith',\n",
       " 'Started',\n",
       " 'Supervised',\n",
       " 'Syntax',\n",
       " 'URL',\n",
       " 'Visualization',\n",
       " 'Web',\n",
       " 'a',\n",
       " 'analysis...',\n",
       " 'and',\n",
       " 'are',\n",
       " 'artificial',\n",
       " 'be',\n",
       " 'can',\n",
       " 'core',\n",
       " 'created',\n",
       " 'data',\n",
       " 'defines',\n",
       " 'easy',\n",
       " 'for',\n",
       " 'framework',\n",
       " 'functions...',\n",
       " 'in',\n",
       " 'intelligence...',\n",
       " 'is',\n",
       " 'language...',\n",
       " 'learning',\n",
       " 'learning...',\n",
       " 'library',\n",
       " 'lightweight',\n",
       " 'machine',\n",
       " 'of',\n",
       " 'patterns',\n",
       " 'popular',\n",
       " 'programming',\n",
       " 'structure',\n",
       " 'subfield',\n",
       " 'syntax',\n",
       " 'to',\n",
       " 'type',\n",
       " 'understand...',\n",
       " 'using',\n",
       " 'various',\n",
       " 'versatile',\n",
       " 'views...',\n",
       " 'visualization...',\n",
       " 'web',\n",
       " 'with'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. apply to all row in panda df , by create new column \"Terms\"\n",
    "df[\"Terms\"] = df[\"Content\"].apply(tokenize_content)\n",
    "df[[\"Document ID\", \"Terms\"]]\n",
    "def preprocess_terms(terms):\n",
    "    # Define a set of common stop words\n",
    "    stop_words = set([\n",
    "        \"a\", \"an\", \"the\", \"and\", \"is\", \"in\", \"it\", \"to\", \"of\", \"for\", \"on\", \"with\", \"as\"\n",
    "    ])\n",
    "# unique_terms ={term for document in lis for term in document.split()}\n",
    "\n",
    "# unique_terms\n",
    "\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "    terms = [term.lower().strip(string.punctuation) for term in terms]\n",
    "  # Remove stop words\n",
    "    terms = [term for term in terms if term not in stop_words]\n",
    "    \n",
    "    return terms\n",
    "# your code here....\n",
    "unique_terms = {term for doc in df[\"Terms\"] for term in doc}\n",
    "unique_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e00676c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Analysis',\n",
       " 'Basic',\n",
       " 'Clark',\n",
       " 'Creating',\n",
       " 'Data',\n",
       " 'DataFrames',\n",
       " 'Davis',\n",
       " 'Development',\n",
       " 'Doe',\n",
       " 'Emily',\n",
       " 'Flask',\n",
       " 'Getting',\n",
       " 'Introduction',\n",
       " 'Jane',\n",
       " 'John',\n",
       " 'Johnson',\n",
       " 'Learning',\n",
       " 'Machine',\n",
       " 'Matplotlib',\n",
       " 'Mike',\n",
       " 'Pandas',\n",
       " 'Pandas...',\n",
       " 'Plots',\n",
       " 'Python',\n",
       " 'Python...',\n",
       " 'Robert',\n",
       " 'Routing',\n",
       " 'Scikit-Learn',\n",
       " 'Smith',\n",
       " 'Started',\n",
       " 'Supervised',\n",
       " 'Syntax',\n",
       " 'URL',\n",
       " 'Visualization',\n",
       " 'Web',\n",
       " 'a',\n",
       " 'analysis...',\n",
       " 'and',\n",
       " 'are',\n",
       " 'artificial',\n",
       " 'be',\n",
       " 'can',\n",
       " 'core',\n",
       " 'created',\n",
       " 'data',\n",
       " 'defines',\n",
       " 'easy',\n",
       " 'for',\n",
       " 'framework',\n",
       " 'functions...',\n",
       " 'in',\n",
       " 'intelligence...',\n",
       " 'is',\n",
       " 'language...',\n",
       " 'learning',\n",
       " 'learning...',\n",
       " 'library',\n",
       " 'lightweight',\n",
       " 'machine',\n",
       " 'of',\n",
       " 'patterns',\n",
       " 'popular',\n",
       " 'programming',\n",
       " 'structure',\n",
       " 'subfield',\n",
       " 'syntax',\n",
       " 'to',\n",
       " 'type',\n",
       " 'understand...',\n",
       " 'using',\n",
       " 'various',\n",
       " 'versatile',\n",
       " 'views...',\n",
       " 'visualization...',\n",
       " 'web',\n",
       " 'with'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Implement a preprocessing function that converts terms to lowercase, removes punctuation, and removes common stop words.\n",
    "    # Create another new column \"Terms_preprocessed\"\n",
    "def preprocess_terms(terms):\n",
    "    # Define a set of common stop words\n",
    "    stop_words = set([\n",
    "        \"a\", \"an\", \"the\", \"and\", \"is\", \"in\", \"it\", \"to\", \"of\", \"for\", \"on\", \"with\", \"as\"\n",
    "    ])\n",
    "    \n",
    "      # Remove punctuation and convert to lowercase\n",
    "    terms = [term.lower().strip(string.punctuation) for term in terms]\n",
    "    \n",
    "    # Remove stop words\n",
    "    terms = [term for term in terms if term not in stop_words]\n",
    "    \n",
    "    return terms\n",
    "\n",
    "# your code here....\n",
    "unique_terms = {term for doc in df[\"Terms\"] for term in doc}\n",
    "unique_terms\n",
    "\n",
    "\n",
    "# unique_terms ={term for document in lis for term in document.split()}\n",
    "\n",
    "# unique_terms\n",
    " \n",
    "    \n",
    "# import json\n",
    "# res=json.loads(lis[0])\n",
    "# res=res['sections']\n",
    "# doc_term_matrix = []\n",
    "# for x in res:\n",
    "# #     doc_term_matrix[term]=[]\n",
    "#     print(x.values())\n",
    "#     unique_terms ={term for document in x.values() for term in document.split()}\n",
    "# #      doc_term_matrix[term]=[]\n",
    "#     doc_term_matrix.append(unique_terms)\n",
    "\n",
    "\n",
    "# doc_term_matrix\n",
    "# unique_terms\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b155ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533e73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0c49e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Introduction': {1, 2, 4, 5},\n",
       " 'to': {1, 2, 4, 5},\n",
       " 'Python': {1},\n",
       " 'John': {1},\n",
       " 'Doe': {1},\n",
       " 'Getting': {1, 3},\n",
       " 'Started': {1, 3},\n",
       " 'is': {1, 2, 3, 4, 5},\n",
       " 'a': {1, 2, 3, 4, 5},\n",
       " 'versatile': {1, 5},\n",
       " 'programming': {1},\n",
       " 'language...': {1},\n",
       " 'Basic': {1},\n",
       " 'Syntax': {1},\n",
       " 'syntax': {1},\n",
       " 'easy': {1},\n",
       " 'understand...': {1},\n",
       " 'Data': {2, 5},\n",
       " 'Analysis': {2},\n",
       " 'with': {2, 3, 4, 5},\n",
       " 'Pandas': {2},\n",
       " 'Jane': {2},\n",
       " 'Smith': {2},\n",
       " 'popular': {2},\n",
       " 'library': {2, 5},\n",
       " 'for': {2, 3, 5},\n",
       " 'data': {2, 5},\n",
       " 'analysis...': {2},\n",
       " 'DataFrames': {2},\n",
       " 'are': {2},\n",
       " 'core': {2},\n",
       " 'structure': {2},\n",
       " 'in': {2, 3, 5},\n",
       " 'Pandas...': {2},\n",
       " 'Web': {3},\n",
       " 'Development': {3},\n",
       " 'Flask': {3},\n",
       " 'Mike': {3},\n",
       " 'Johnson': {3},\n",
       " 'lightweight': {3},\n",
       " 'web': {3},\n",
       " 'framework': {3},\n",
       " 'Python...': {3},\n",
       " 'Routing': {3},\n",
       " 'defines': {3},\n",
       " 'URL': {3},\n",
       " 'patterns': {3},\n",
       " 'and': {3},\n",
       " 'views...': {3},\n",
       " 'Machine': {4},\n",
       " 'Learning': {4},\n",
       " 'Scikit-Learn': {4},\n",
       " 'Emily': {4},\n",
       " 'Davis': {4},\n",
       " 'learning': {4},\n",
       " 'subfield': {4},\n",
       " 'of': {4},\n",
       " 'artificial': {4},\n",
       " 'intelligence...': {4},\n",
       " 'Supervised': {4},\n",
       " 'type': {4},\n",
       " 'machine': {4},\n",
       " 'learning...': {4},\n",
       " 'Visualization': {5},\n",
       " 'Matplotlib': {5},\n",
       " 'Robert': {5},\n",
       " 'Clark': {5},\n",
       " 'visualization...': {5},\n",
       " 'Creating': {5},\n",
       " 'Plots': {5},\n",
       " 'can': {5},\n",
       " 'be': {5},\n",
       " 'created': {5},\n",
       " 'using': {5},\n",
       " 'various': {5},\n",
       " 'functions...': {5}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty inverted index dictionary\n",
    "# Build the inverted index\n",
    "# Initialize an empty inverted index dictionary\n",
    "inverted_index = {}\n",
    "...# Build the inverted index\n",
    "for index, row in df.iterrows():\n",
    "    document_id = row[\"Document ID\"]\n",
    "    terms = row[\"Terms\"]\n",
    "    \n",
    "    # Update the inverted index with terms and document IDs\n",
    "    for term in terms:\n",
    "        if term not in inverted_index:\n",
    "            inverted_index[term] = set()\n",
    "        inverted_index[term].add(document_id)\n",
    "\n",
    "# Display the inverted index\n",
    "inverted_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15a87d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform boolean operations on postings lists for Boolean search operations\n",
    "posting_list = inverted_index['Visualization']\n",
    "posting_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283eeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d1226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fe9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27def6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. \"Python\" OR \"Pandas\"\n",
    "def or_postings(posting1, posting2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = list()\n",
    "    while p1 < len(posting1) and p2 < len(posting2):\n",
    "        if posting1[p1] == posting2[p2]:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        elif posting1[p1] > posting2[p2]:\n",
    "            result.append(posting2[p2])\n",
    "            p2 += 1\n",
    "        else:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "    while p1 < len(posting1):\n",
    "        result.append(posting1[p1])\n",
    "        p1 += 1\n",
    "    while p2 < len(posting2):\n",
    "        result.append(posting2[p2])\n",
    "        p2 += 1\n",
    "    return result\n",
    "\n",
    "pl_1 = list(inverted_index['Python'])\n",
    "pl_2 = list(inverted_index['Pandas'])\n",
    "or_postings(pl_1,pl_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "131fdcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. \"Python\" AND \"data\"\n",
    "def and_postings(posting1, posting2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = list()\n",
    "    while p1 < len(posting1) and p2 < len(posting2):\n",
    "        if posting1[p1] == posting2[p2]:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        elif posting1[p1] == posting2[p2]:\n",
    "            p2 += 1\n",
    "        else:\n",
    "            p1 += 1\n",
    "    return result\n",
    "\n",
    "pl_1 = list(inverted_index['Python'])\n",
    "pl_2 = list(inverted_index['Data'])\n",
    "and_postings(pl_1,pl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4824b570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b929397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80680485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b13a6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ffb4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cf56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36623a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6c8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
